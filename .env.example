# Database
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/synthesis

# Anthropic (Required)
ANTHROPIC_API_KEY=sk-ant-api03-your-key-here

# Ollama (Local LLM)
OLLAMA_BASE_URL=http://localhost:11434
EMBEDDING_MODEL=nomic-embed-text

# Voyage (Optional - Cloud embeddings alternative)
# VOYAGE_API_KEY=pa-your-key-here

# Server Configuration
NODE_ENV=development
SERVER_PORT=3333
WEB_PORT=5173

# Storage
STORAGE_PATH=./storage

# MCP Server
MCP_PORT=3334
MCP_MODE=stdio

# LLM Toggle (false = Claude, true = Ollama)
USE_LOCAL_LLM=false

# Phase 8: Hybrid Search & Multi-Provider Embeddings

# Search Configuration
# Set SEARCH_MODE to 'hybrid' to enable Reciprocal Rank Fusion (defaults to vector-only).
SEARCH_MODE=vector
# Enable trust scoring to boost official and fresh sources.
ENABLE_TRUST_SCORING=false
# Hybrid weighting controls: higher vector weight favors semantic similarity.
HYBRID_VECTOR_WEIGHT=0.7
HYBRID_BM25_WEIGHT=0.3
# Default language for PostgreSQL full-text search.
FTS_LANGUAGE=english

# Embedding Providers
# Ollama is free/local; OpenAI and Voyage require paid API keys.
DOC_EMBEDDING_PROVIDER=ollama
CODE_EMBEDDING_PROVIDER=voyage
WRITING_EMBEDDING_PROVIDER=openai

# External Embedding API Keys
OPENAI_API_KEY=
VOYAGE_API_KEY=

# Phase 12: Re-ranking
# Set to 'bge' for local reranker or 'cohere' when Cohere API key configured.
RERANKER_PROVIDER=none
# Cohere API key used when RERANKER_PROVIDER=cohere
COHERE_API_KEY=
